hadoop dfs -put '/home/neeraj/Downloads/Crimes_2001_to_present.csv' /project1/crime_data_analysis/

a = LOAD '/project1/crime_data_analysis/Crimes_2001_to_present.csv' using PigStorage(',') 
AS (id:int,caseNumber:chararray,arrestDate:chararray,block:chararray,iucr:chararray,primarytype:chararray,description:chararray,locationDesc:chararray,
arrest:chararray,domestic:chararray,beat:chararray,district:chararray,ward:chararray,communityArea:chararray,FBICode:chararray,
xCordinate:chararray,yCordinate:chararray,year:int);

dump a;

/* remove empty tuples*/
b = filter a by caseNumber != '';

dump b;

/* get only date for camparision*/
c = foreach b generate id,SUBSTRING(arrestDate,0,10);
dump c;

d = filter c by (ToDate($1,'MM/dd/yyyyy') > ToDate('09/30/2014','MM/dd/yyyyy') AND ToDate($1,'MM/dd/yyyyy') < ToDate('10/31/2015','MM/dd/yyyyy'));

dump d;

/* this is required to get COUNT() function work*/
e = group d all;

dump e;

f = foreach e generate COUNT($1);

dump f;

/* 244102*/
